{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# Gloabl seaborn Theme\n",
    "sns.set_theme(style=\"whitegrid\", palette=\"pastel\")\n",
    "import math\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.stats._result_classes import PearsonRResult\n",
    "import pandas as pd\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datetime ISO 8601 Format to Timestamp, TZ='America/Bogota' -05:00\n",
    "def to_timestamp(datetime_iso8601):\n",
    "    # datetime_iso8601 = '2023-03-17T00:00:00-05:00'\n",
    "    return int(datetime.fromisoformat(datetime_iso8601).timestamp() * 1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datetime ISO 8601 Format to Timestamp\n",
    "#to_timestamp('2023-03-17T00:00:00-05:00')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Request to InfluxDB API REST\n",
    "def request_influxdb(sql_query):\n",
    "    endpoint = \"http://influxdb.canair.io:8086/query\"\n",
    "    database = \"canairio\"\n",
    "    parameters = {\n",
    "        'db': database,\n",
    "        'q': sql_query,\n",
    "        'epoch': 'ms'\n",
    "    }\n",
    "    # To get response as CSV text\n",
    "    headers = {'Accept': 'application/csv'}\n",
    "    # GET Request\n",
    "    return requests.get(endpoint, params=parameters, headers=headers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Query Tangaras\n",
    "def query_tangaras(start_timestamp, end_timestamp):\n",
    "    # Period DateTime\n",
    "    period_time = f\"time >= {start_timestamp}ms AND time <= {end_timestamp}ms\"\n",
    "    # SQL\n",
    "    sql_query = \"SELECT DISTINCT(geo) AS \\\"geohash\\\" \"\\\n",
    "                \"FROM \\\"fixed_stations_01\\\" WHERE \"\\\n",
    "                \"(\\\"geo3\\\" = 'd29') AND \"\\\n",
    "                f\"{period_time} \"\\\n",
    "                \"GROUP BY \\\"name\\\";\"\n",
    "    return sql_query\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Query Data Sensors\n",
    "def query_data(tangaras, start_timestamp, end_timestamp, datatype='pm25'):\n",
    "    # datatype = ['pm25', 'tmp', 'hum']\n",
    "    # Period DateTime\n",
    "    period_time = f\"time >= {start_timestamp}ms AND time <= {end_timestamp}ms\"\n",
    "    # SQL Datatype by Tangara Sensor\n",
    "    sql_query = \"\"\n",
    "    for mac in tangaras['MAC'].to_list():\n",
    "        sql_query += f\"SELECT \\\"name\\\", last(\\\"{datatype}\\\") \"\\\n",
    "                    \"FROM \\\"fixed_stations_01\\\" WHERE \"\\\n",
    "                    f\"(\\\"name\\\" = '{mac}') AND \"\\\n",
    "                    f\"{period_time} \" \\\n",
    "                    \"GROUP BY time(30s) fill(none); \"\n",
    "    return sql_query[:-2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Histograms\n",
    "def histplots(data_sensors):\n",
    "    data_sensors = data_sensors.interpolate(method='time')\n",
    "    size = len(data_sensors.columns)\n",
    "    # Canvas\n",
    "    fig, axes = plt.subplots(math.ceil(size/2), 2, figsize=(20, 40), constrained_layout=True)\n",
    "    fig.suptitle('Histograms - PM25', fontsize=20)\n",
    "    # Plot\n",
    "    k = 0\n",
    "    for i in range(0, math.ceil(size/2)):\n",
    "        for j in range(0, 2):\n",
    "            if k <= size:\n",
    "                sns.histplot(ax=axes[i, j], data=data_sensors[data_sensors.columns[k]], kde=True)#, bins=50\n",
    "            k += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Boxplots\n",
    "def boxplots(data_sensors):\n",
    "    data_sensors = data_sensors.interpolate(method='time')\n",
    "    size = len(data_sensors.columns)\n",
    "    # Canvas\n",
    "    fig, axes = plt.subplots(math.ceil(size/2), 2, figsize=(20, 40), constrained_layout=True)\n",
    "    fig.suptitle('Boxplots - PM25', fontsize=20)\n",
    "    # Plot\n",
    "    k = 0\n",
    "    for i in range(0, math.ceil(size/2)):\n",
    "        for j in range(0, 2):\n",
    "            if k <= size:\n",
    "                sns.boxplot(ax=axes[i, j], data=data_sensors[data_sensors.columns[k]], orient=\"h\")#, x=data_sensors[data_sensors.columns[k]]\n",
    "                axes[i, j].set_ylabel(data_sensors.columns[k])\n",
    "            k += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Lineplots\n",
    "def lineplots(data_sensors):\n",
    "    data_sensors = data_sensors.interpolate(method='time')\n",
    "    size = len(data_sensors.columns)\n",
    "    # Canvas\n",
    "    fig, axes = plt.subplots(math.ceil(size/2), 2, figsize=(20, 40), constrained_layout=True)\n",
    "    fig.suptitle('Timeline - PM25', fontsize=20)\n",
    "    # Plot\n",
    "    k = 0\n",
    "    for i in range(0, math.ceil(size/2)):\n",
    "        for j in range(0, 2):\n",
    "            if k <= size:\n",
    "                sns.lineplot(ax=axes[i, j], data=data_sensors[data_sensors.columns[k]])\n",
    "            k += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_data(data_sensors, threshold_data=80):\n",
    "    # Missing data\n",
    "    to_be_checked = []\n",
    "    # Each sensor to be checked\n",
    "    for sensor in data_sensors.columns:\n",
    "        total = data_sensors[sensor].shape[0]\n",
    "        missing_data = round(data_sensors[sensor].isna().sum() * 100 / total)\n",
    "        data = round(data_sensors[sensor].count() * 100 / total)\n",
    "        # Threshold\n",
    "        if data < threshold_data:\n",
    "            to_be_checked.append({'ID': sensor, 'Data': f'{data}%', 'Missing': f'{missing_data}%'})\n",
    "    # Sensors to be check\n",
    "    return to_be_checked\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation(sensors_to_evaluate, id_reference_sensor, threshold_corr=0.9):\n",
    "    sensors_to_evaluate = sensors_to_evaluate.interpolate(method='time')\n",
    "    ts_reference = sensors_to_evaluate[id_reference_sensor]\n",
    "    # Wron correlation data\n",
    "    to_be_checked = []\n",
    "    # Each sensor to be checked\n",
    "    for id_target_sensor in sensors_to_evaluate.columns:\n",
    "        if id_target_sensor != id_reference_sensor:\n",
    "            ts_target = sensors_to_evaluate[id_target_sensor]\n",
    "            # Pearson correlation coefficient\n",
    "            corr, _ = pearsonr(ts_reference, ts_target) if ts_target.std() != 0 else PearsonRResult(0,0,alternative=0,n=0)\n",
    "            # Threshold\n",
    "            if corr < threshold_corr:\n",
    "                to_be_checked.append({'Reference': {'ID': id_reference_sensor, 'Data': len(ts_reference), 'Freq': ts_reference.index.freq},\n",
    "                                    'Target': {'ID': id_target_sensor, 'Data': len(ts_target), 'Freq': ts_target.index.freq},\n",
    "                                    'Correlation': corr})\n",
    "    # Sensors to be check\n",
    "    return to_be_checked\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
